# Chapter 1 머신러닝

## 머신러닝 시스템의 종류

* ### 지도, 비지도, 준지도, 강화학습 

  *사람의 감독하에 훈련하는지 아닌지*

  #### 지도학습

  ---

  알고리즘에 주입하는 훈련 데이터에 **레이블**이라는 원하는 답이 포함되는 학습

  >k - 최근접 이웃
  >
  >선형 회귀
  >
  >로지스틱 회귀
  >
  >서포트 벡터 머신(SVM)
  >
  >결정 트리 & 랜덤 포레스트
  >
  >신경망

  #### 비지도 학습

  ---

  훈련데이터에 **레이블이 없는 학습**, 즉 시스템이 아무런 도움 없이 학습해야함

  >***군집***
  >
  >> k - 평균
  >>
  >> DBSCAN
  >>
  >> 계층 군집 분석
  >>
  >> 이상치 탐지와 특이치 탐지
  >>
  >> 원 - 클래스
  >>
  >> 아이솔레이션 포레스트
  >
  >***시각화 & 차원축소***
  >
  >> 주성분 분석(PCA)
  >>
  >> 커널 PCA
  >>
  >> 지역적 선형 임베딩
  >>
  >> t-SNE
  >
  >연관 규칙 학습
  >
  >> 어프라이어리
  >>
  >> 이클넷

  ✔  **차원 축소**: 너무 많은 정보를 잃지 않으면서 데이터를 간소화하는 법( ex)상관관계가 있는 여러특성을 하나로 합치는 것 )  

  ✔  **이상치 탐지**: 시스템이 훈련하는 동안 대부분 정상 샘플을 만나 인식할 수 있도록 이상한 값을 탐지하는 것

  ✔  **특이치 탐지**: 훈련세트에 있는 모든 샘플과 달라 보이는 새로은 샘플을 탐지하는 것이 목적

  ✔  **연관 규칙학습**: 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는 학습

  #### 준지도 학습

  ---

  훈련데이터에 **레이블이 있는 데이터와 없는 데이터가 섞인 학습**

  ✔ 대부분의 준지도 학습 알고리즘: 지도학습 + 비지도 학습

  #### 강화학습

  ---

  학습하는 시스템: 에이전트

  환경을 관찰하여 행동을 실행하고 그 결과로 보상 혹은 벌점을 받아 시간이 지나면서 가장 큰 보상을 얻기위해 정책이라고 부르는 최상의 전략을 스스로 학습하는 것

* ### 온라인, 배치 학습

  *실시간으로 점진적인 학습을 하는지 아닌지*

  #### 온라인 학습

  ---

  온라인 학습에서는 데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킵니다. 온라인 학습은 연속적으로 데이터를 받고 (예를 들면 주식가격) 빠른 변화에 스스로 적응해야 하는 시스템에 적합합니다.

  #### 배치학습

  ---

  배치 학습에서는 시스템이 점진적으로 학습할 수 없습니다. 가용한 데이터를 모두 사용해 훈련시켜야 합니다. 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습없이 실행됩니다. 즉, 학습한 것을 단지 적용만 합니다. 이를 오프라인 학습이라고 합니다.

* ### 사례 기반 학습, 모델 기반 학습 

  *단순히 알고있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지* 

   *과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는 지* 

  #### 사례 기반 학습

  ---

  사례 기반 학습에서는 시스템이 사례를 기억함으로써 학습합니다(대표적으로 스팸메일). 그리고 유사도 측정을 사용해 새로운 데이터에 일반화합니다.

  #### 모델 기반 학습

  ---

  모델 기반 학습에서는 샘플들의 모델을 만들어 예측에 사용합니다.

  

## 머신러닝의 주요 도전과제

* ### 나쁜 데이터 

  #### 충분하지 않은 양의 훈련 데이터

  ---

  머신러닝 알고리즘이 잘 작동하려면 데이터의 수가 많아야 한다.

  

  #### 대표성이 없는 훈련 데이터

  ---

  일반화하려는 사례들을 대표하는 훈련세트를 사용하는 것이 매우 중요하지만 생각보다 어려움

  ✔  **샘플링 잡음**: 샘플이 작을 때 우연에 의한 대표성 없는 데이터가 생기는 것

  ✔  **샘플링 편향**: 샘플이 클 때 표본 추출 방법에 잘못되어 대표성을 띄지 못하게 되는 것

  

  #### 낮은 품질의 데이터

  ---

  훈련데이터에 **에러, 이상치, 잡음** 으로 가득한 데이터는 품질이 낮다고 할 수 있다.

  

  #### 관련 없는 특성

  ---

  훈련데이터에 관련 없는 특성이 적고 관련있는 특성이 충분해야 시스템을 학습시킬 수 있다. 

  ✔  **특성공학**: 훈련에 사용할 데이터의 좋은 특성을 찾는 과정

  

* ### 나쁜 알고리즘

  #### 훈련 데이터 과대적합(Overfitting)

  ---

  모델이 훈련데이터에 너무 잘 맞는 경우 일반성이 떨어지는 문제가 발생한다.

  ✔  **해결방안**

  >* 파라미터 수가 적은 모델을 선택하거나, 훈련데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가해 단순화 시킨다.
  >* 훈련데이터들을 많이 모은다.
  >* 훈련 데이터의 잡음을 줄인다. ex)오류 데이터 수정과 이상치 제거

  

  #### 훈련 데이터 과소적합(Underfitting)

  ---

  모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어나는 문제.

  ✔  **해결방안**

  >* 모델 파라미터가 더 많은 강력한 모델을 선택한다.
  >* 학습 알고리즘에 더 좋은 특성을 제공한다.(특성공학)
  >* 모델의 제약을 줄인다. ex) 규제 하이퍼파라미터를 줄인다.

  

## 테스트와 검증

* ### 하이퍼파라미터 튜닝과 모델 선택

  ㅇ Test 세트를 사용하여 모델을 평가한다. 

  ✔  **Holdout 검증**: 훈련세트의 일부를 떼어내어 여러후보 모델을 평가하고 가장 좋은 하나를 선택하는 방법

  데이터 = 훈련데이터(Train data) + 검증데이터(Validation data) + 테스트데이터(Test data) 

  ✔  **Holdout 검증과정** 

  >1. 검증 세트를 뺀 훈련세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델들을 훈련한다.
  >2. 검증세트에서 가장 높은 성능을 내는 모델을 선택한다.
  >3. 검증과정이 끝나면 최선의 모델을 전체 훈련세트에서 훈련하여 최종모델을 만든다.
  >4. 최종모델을 Test data를 통해 평가하여 일반화 오차를 추정한다.

  ✔  **교차검증(cross - validation)**

  ---

  검증 데이터가 너무 작으면 모델이 정확하게 평가되지 않고

  검증 데이터가 너무 크면 남은 훈련 데이터가 전제 훈련 데이터에 비해 너무 작아져 문제가 생긴다

  따라서 작은 검증 데이터를 여러개 사용해 반복적인 검증을 수행한다.

  검증세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 데이터를 통해 평가하고 이를 평균하면 훨씬 정확한 성능을 측정할 수 있다.

  훈련시간이 검증 데이터셋 수에 비례해 늘어난다는 단점도 있다.

   















